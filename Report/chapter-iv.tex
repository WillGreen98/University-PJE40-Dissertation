\chapter{Requirements and Planning}

This chapter outlines the desired requirements which are necessary for this project to work and to have met the criteria proposed, it also includes additional requirements such as potential requirements and unnecessary but topical requirements. In section 3.1.3, the model flowchart displays requirements must be detailed as part of the SDLC for project ambitions and solution scope; all requirements listed are relevant to a machine learning NLP focused model, seen as a process orientated requirement.

\section{Requirement Elicitation}

Requirement elicitation for this project started by defining its scope, planning a potential solution and desired outcome to further have a discussion with the project supervisor, to gain requirement insight. The project’s functionality and capabilities were outlined in-order for the functional and non-functional requirements to be identified.

As no human parties were involved, other than the developer and project supervisor, no external input was involved. Therefore, the requirement elicitation process primarily focused on academic research and existing applications of similar intent. Existing text classification machine learning models provided insight to potential requirements; the research covered in the literature review (section 2) under existing applications highlighted key areas of interest. This project benefitted from deriving requirements seen from a process perspective opposed to traditional methods such as a questionnaire, for example a procedural step within the machine-learning process i.e., model must clean data.

\subsection{Requirement Research of Current Models}

A generalised overview of functional requirements of a text classification model:

\begin{enumerate}
    \item Parse Data
    \item Pre-processing of Data
    \begin{enumerate}
        \item Tokenization
        \item Vectorization
    \end{enumerate}
\item Text pre-processing
\item Clean data
    \begin{enumerate}
        \item Remove empty data, useless punctuation, and unnecessary stop words
        \item Stem the words
    \end{enumerate}
\item Feature Engineering and Extraction
\item Feed clean dataset into model
\item Train model
\item Tune hyperparameters
    \begin{enumerate}
        \item Number of layers in model and units per layer
        \item Dropout rate
        \item Learning rate
        \item Kernel size
        \item Embedding
    \end{enumerate}
\item Evaluate model
\end{enumerate}

\section{Requirement Specification}

This project makes use of the MoSCoW prioritisation technique whereby requirements are defined as “Must Have”, “Should Have”, “Could have”, and “Won’t Have at this Time”. The four categories of MoSCoW can be translated to Core, Base, Additional, and Future Work. This project acknowledges the disadvantages of the MoSCoW technique; however, its simplicity outweighs the disadvantages in this environment.

\section{Constraints}

\begin{itemize}
    \item Issues locating appropriate openly sourced datasets of existing student feedback.
    \item Accuracy of model given located datasets.
    \item Components of the model may not communicate well with other aspects.
    \item Programming and language concern.
    \item Logistical issues.
\end{itemize}

Defining potential constraints of this project aided identifying its functional and non-functional requirements as there was an insight as to what may work or not work when in the development phase, these requirements are listed below with the appropriate level of prioritisation.

\section{Functional Requirements}

\begin{itemize}
    \item The model must correctly parse a given dataset such that the correctness of the original dataset is intact.
    \item The model must pre-process the dataset into a given method: tokens/vectors.
    \item The model must pre-process the text within the dataset into specific categories.
    \item The model must clean the text such that cleaning involves the removal of empty fields within a CSV file, any useless or incorrect punctuation, and unnecessary stop words.
    \item The model must take the clean data and categories stem words.
    \item The model must provide an analytical solution in which communicates with processing features.
    \item The model solution must be agnostic towards data types, data sensors, vendor (mostly universities or colleges) and data creation date.
    \item The model may report analysis in real-time with graphs or training data within the CLI, this includes any abnormalities which might need deeper analysis to be useful data.
    \item The model may create an interactable alert so the user can decide on how to proceed.
    \item The model must produce a machine learning implementation that learns and is trained on sample data that is then extrapolated into a useable asset.
    \item The model must execute statistical analysis on the yielded information which is generated for future examination.
    \item The model must classify text.
    \item The model may predict future student evaluations.
    \item The model should save outputted data to a local text file
    \item The model won’t have a GUI (can be developed for future work).
\end{itemize}

\begin{itemize}
    \item \textbf{\textit{Must Have}}
        \begin{itemize}\label{FMH}
            \item MH1
        \end{itemize}
    \item \textbf{\textit{Should Have}}
        \begin{itemize}\label{FSH}
            \item SH1
        \end{itemize}
    \item \textbf{\textit{Could Have}}
        \begin{itemize}\label{FCH}
            \item CH1
        \end{itemize}
    \item \textbf{\textit{Won't Have}}
        \begin{itemize}\label{FWH}
            \item WH1
        \end{itemize}
\end{itemize}

\section{Non---Functional Requirements}

\begin{itemize}
    \item The model may be scalable for multiple datasets or machines.
    \item The model may yield predictions or results limited to the scope of a set asset.
    \item The model may yield results across several datasets.
    \item The model must yield maximum theoretical performance for its implementation, this includes:
    \item Correct potential true positives
    \item Correct potential false positives
    \item Account for and correct false negatives
    \item Recall of data and specifics
    \item The model must yield optimal precision of data and classification.
    \item The model must provide and produce an accurate F-Score.
    \item The model must run within an acceptable timeframe for a given machine, e.g., testing must not run over 24hrs for an appropriate dataset.
    \item The model must be maintainable within its set scope, overdeveloping or under developing can lead to bugs or broken links such as outdated APIs.
    \item The model must be useable for a lay person who wants to classify text (school admin).
\end{itemize}

\begin{itemize}
    \item \textbf{\textit{Must Have}}
        \begin{itemize}\label{NFMH}
            \item MH1
        \end{itemize}
    \item \textbf{\textit{Should Have}}
        \begin{itemize}\label{NFSH}
            \item SH1
        \end{itemize}
    \item \textbf{\textit{Could Have}}
        \begin{itemize}\label{NFCH}
            \item CH1
        \end{itemize}
    \item \textbf{\textit{Won't Have}}
        \begin{itemize}\label{NFWH}
            \item WH1
        \end{itemize}
\end{itemize}

\section{Challenges in Requirements}

Challenges

\section{Cost Prediction}

This project will not have any costs associated with or throughout the development. However, future development may include renting server space for better spec machines to run training of this model.